# Replication

First of all created two Linux users with GitHub names of my Lab partner and me, then added the users on Hue, which creates home directories in HDFS.

Generated a 500MB file with `teragen`:
```
[spinatelli@ip-172-0-0-4 ~]$ hadoop jar /opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/jars/hadoop-examples.jar teragen 5242880 /user/patelliandrea/teragen_data
16/11/15 04:45:11 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
16/11/15 04:45:11 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
16/11/15 04:45:11 INFO terasort.TeraSort: Generating 5242880 using 1
16/11/15 04:45:11 INFO mapreduce.JobSubmitter: number of splits:1
16/11/15 04:45:12 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1958949546_0001
16/11/15 04:45:12 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/11/15 04:45:12 INFO mapreduce.Job: Running job: job_local1958949546_0001
16/11/15 04:45:12 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/11/15 04:45:12 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/11/15 04:45:12 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/11/15 04:45:12 INFO mapred.LocalJobRunner: Waiting for map tasks
16/11/15 04:45:12 INFO mapred.LocalJobRunner: Starting task: attempt_local1958949546_0001_m_000000_0
16/11/15 04:45:12 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/11/15 04:45:12 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/11/15 04:45:12 INFO mapred.MapTask: Processing split: org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@41a30e46
16/11/15 04:45:13 INFO mapreduce.Job: Job job_local1958949546_0001 running in uber mode : false
16/11/15 04:45:13 INFO mapreduce.Job:  map 0% reduce 0%
16/11/15 04:45:18 INFO mapred.LocalJobRunner:
16/11/15 04:45:18 INFO mapred.Task: Task:attempt_local1958949546_0001_m_000000_0 is done. And is in the process of committing
16/11/15 04:45:18 INFO mapred.LocalJobRunner:
16/11/15 04:45:18 INFO mapred.Task: Task attempt_local1958949546_0001_m_000000_0 is allowed to commit now
16/11/15 04:45:18 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1958949546_0001_m_000000_0' to hdfs://ip-172-0-0-4.eu-central-1.compute.internal:8020/user/patelliandrea/teragen_data/_temporary/0/task_local1958949546_0001_m_000000
16/11/15 04:45:18 INFO mapred.LocalJobRunner: map
16/11/15 04:45:18 INFO mapred.Task: Task 'attempt_local1958949546_0001_m_000000_0' done.
16/11/15 04:45:18 INFO mapred.LocalJobRunner: Finishing task: attempt_local1958949546_0001_m_000000_0
16/11/15 04:45:18 INFO mapred.LocalJobRunner: map task executor complete.
16/11/15 04:45:18 INFO mapreduce.Job:  map 100% reduce 0%
16/11/15 04:45:18 INFO mapreduce.Job: Job job_local1958949546_0001 completed successfully
16/11/15 04:45:18 INFO mapreduce.Job: Counters: 21
        File System Counters
                FILE: Number of bytes read=276325
                FILE: Number of bytes written=572793
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=0
                HDFS: Number of bytes written=524288000
                HDFS: Number of read operations=4
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=3
        Map-Reduce Framework
                Map input records=5242880
                Map output records=5242880
                Input split bytes=82
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=55
                Total committed heap usage (bytes)=180355072
        org.apache.hadoop.examples.terasort.TeraGen$Counters
                CHECKSUM=11257830824958050
        File Input Format Counters
                Bytes Read=0
        File Output Format Counters
                Bytes Written=524288000
```

The file generated by `patelliandrea` was then copied to my cluster using `distcp`. To be able to do this, both clusters had to have the `dfs.client.use.datanode.hostname` property set to `true`, to use hostnames instead of the private IPs of the Datanodes.

```
[spinatelli@ip-172-0-0-4 ~]$ hadoop distcp hdfs://padrinocluster1:8020/user/spinatelli/teragen_data/part-m-00000 teragen_data/
16/11/15 05:44:22 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, overwrite=false, skipCRC=false, blocking=true, numListstatusThreads=0, maxMaps=20, mapBandwidth=100, sslConfigurationFile='null', copyStrategy='uniformsize', preserveStatus=[], preserveRawXattrs=false, atomicWorkPath=null, logPath=null, sourceFileListing=null, sourcePaths=[hdfs://padrinocluster1:8020/user/spinatelli/teragen_data/part-m-00000], targetPath=teragen_data, targetPathExists=false, filtersFile='null'}
16/11/15 05:44:22 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
16/11/15 05:44:22 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
16/11/15 05:44:22 INFO tools.SimpleCopyListing: Paths (files+dirs) cnt = 1; dirCnt = 0
16/11/15 05:44:22 INFO tools.SimpleCopyListing: Build file listing completed.
16/11/15 05:44:22 INFO Configuration.deprecation: io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
16/11/15 05:44:22 INFO Configuration.deprecation: io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
16/11/15 05:44:22 INFO tools.DistCp: Number of paths in the copy list: 1
16/11/15 05:44:22 INFO tools.DistCp: Number of paths in the copy list: 1
16/11/15 05:44:22 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/11/15 05:44:23 INFO mapreduce.JobSubmitter: number of splits:1
16/11/15 05:44:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1345031797_0001
16/11/15 05:44:23 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/11/15 05:44:23 INFO tools.DistCp: DistCp job-id: job_local1345031797_0001
16/11/15 05:44:23 INFO mapreduce.Job: Running job: job_local1345031797_0001
16/11/15 05:44:23 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/11/15 05:44:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/11/15 05:44:23 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
16/11/15 05:44:23 INFO mapred.LocalJobRunner: Waiting for map tasks
16/11/15 05:44:23 INFO mapred.LocalJobRunner: Starting task: attempt_local1345031797_0001_m_000000_0
16/11/15 05:44:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/11/15 05:44:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/11/15 05:44:23 INFO mapred.MapTask: Processing split: file:/tmp/hadoop-spinatelli/mapred/staging/spinatelli34090830/.staging/_distcp-960985588/fileList.seq:0+242
16/11/15 05:44:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/11/15 05:44:23 INFO mapred.CopyMapper: Copying hdfs://padrinocluster1:8020/user/spinatelli/teragen_data/part-m-00000 to hdfs://ip-172-0-0-4.eu-central-1.compute.internal:8020/user/spinatelli/teragen_data
16/11/15 05:44:23 INFO mapred.RetriableFileCopyCommand: Creating temp file: hdfs://ip-172-0-0-4.eu-central-1.compute.internal:8020/user/spinatelli/.distcp.tmp.attempt_local1345031797_0001_m_000000_0
16/11/15 05:44:24 INFO mapreduce.Job: Job job_local1345031797_0001 running in uber mode : false
16/11/15 05:44:24 INFO mapreduce.Job:  map 0% reduce 0%
16/11/15 05:44:29 INFO mapred.LocalJobRunner:
16/11/15 05:44:29 INFO mapred.Task: Task:attempt_local1345031797_0001_m_000000_0 is done. And is in the process of committing
16/11/15 05:44:29 INFO mapred.LocalJobRunner:
16/11/15 05:44:29 INFO mapred.Task: Task attempt_local1345031797_0001_m_000000_0 is allowed to commit now
16/11/15 05:44:29 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1345031797_0001_m_000000_0' to file:/tmp/hadoop-spinatelli/mapred/staging/spinatelli34090830/.staging/_distcp-960985588/_logs/_temporary/0/task_local1345031797_0001_m_000000
16/11/15 05:44:29 INFO mapred.LocalJobRunner: 100.0% Copying hdfs://padrinocluster1:8020/user/spinatelli/teragen_data/part-m-00000 to hdfs://ip-172-0-0-4.eu-central-1.compute.internal:8020/user/spinatelli/teragen_data [500.0M/500.0M]
16/11/15 05:44:29 INFO mapred.Task: Task 'attempt_local1345031797_0001_m_000000_0' done.
16/11/15 05:44:29 INFO mapred.LocalJobRunner: Finishing task: attempt_local1345031797_0001_m_000000_0
16/11/15 05:44:29 INFO mapred.LocalJobRunner: map task executor complete.
16/11/15 05:44:29 INFO mapred.CopyCommitter: Cleaning up temporary work folder: file:/tmp/hadoop-spinatelli/mapred/staging/spinatelli34090830/.staging/_distcp-960985588
16/11/15 05:44:29 INFO mapreduce.Job:  map 100% reduce 0%
16/11/15 05:44:29 INFO mapreduce.Job: Job job_local1345031797_0001 completed successfully
16/11/15 05:44:29 INFO mapreduce.Job: Counters: 23
        File System Counters
                FILE: Number of bytes read=1955057
                FILE: Number of bytes written=2271838
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=524288000
                HDFS: Number of bytes written=524288000
                HDFS: Number of read operations=19
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=2
        Map-Reduce Framework
                Map input records=1
                Map output records=0
                Input split bytes=166
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=37
                Total committed heap usage (bytes)=159907840
        File Input Format Counters
                Bytes Read=274
        File Output Format Counters
                Bytes Written=8
        org.apache.hadoop.tools.mapred.CopyMapper$Counter
                BYTESCOPIED=524288000
                BYTESEXPECTED=524288000
                COPY=1

```

Checked blocks of source file:

```
[spinatelli@ip-172-0-0-4 ~]$ hadoop fsck /user/spinatelli/teragen_data/part-m-00000 -files -blocks
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://ip-172-0-0-4.eu-central-1.compute.internal:50070
FSCK started by spinatelli (auth:SIMPLE) from /172.0.0.4 for path /user/spinatelli/teragen_data/part-m-00000 at Tue Nov 15 05:47:25 EST 2016
/user/spinatelli/teragen_data/part-m-00000 524288000 bytes, 4 block(s):  OK
0. BP-1717843915-172.0.0.4-1479159419351:blk_1073743317_2493 len=134217728 Live_repl=3
1. BP-1717843915-172.0.0.4-1479159419351:blk_1073743318_2494 len=134217728 Live_repl=3
2. BP-1717843915-172.0.0.4-1479159419351:blk_1073743319_2495 len=134217728 Live_repl=3
3. BP-1717843915-172.0.0.4-1479159419351:blk_1073743321_2497 len=121634816 Live_repl=3

Status: HEALTHY
 Total size:    524288000 B
 Total dirs:    0
 Total files:   1
 Total symlinks:                0
 Total blocks (validated):      4 (avg. block size 131072000 B)
 Minimally replicated blocks:   4 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    3
 Average block replication:     3.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          3
 Number of racks:               1
FSCK ended at Tue Nov 15 05:47:25 EST 2016 in 0 milliseconds


The filesystem under path '/user/spinatelli/teragen_data/part-m-00000' is HEALTHY
```

On `patelliandrea`'s cluster the check gave following result:
```
[spinatelli@ip-172-20-0-4 ~]$ hadoop fsck /user/spinatelli/teragen_data/part-m-00000 -files -blocks
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.
Connecting to namenode via http://ip-172-20-0-4.eu-central-1.compute.internal:50070
FSCK started by spinatelli (auth:SIMPLE) from /172.20.0.4 for path /user/spinatelli/teragen_data/part-m-00000 at Tue Nov 15 05:51:12 EST 2016
/user/spinatelli/teragen_data/part-m-00000 524288000 bytes, 4 block(s):  OK
0. BP-567007794-172.20.0.4-1479156642241:blk_1073743371_2547 len=134217728 Live_repl=3
1. BP-567007794-172.20.0.4-1479156642241:blk_1073743372_2548 len=134217728 Live_repl=3
2. BP-567007794-172.20.0.4-1479156642241:blk_1073743373_2549 len=134217728 Live_repl=3
3. BP-567007794-172.20.0.4-1479156642241:blk_1073743374_2550 len=121634816 Live_repl=3
Status: HEALTHY
 Total size:    524288000 B
 Total dirs:    0
 Total files:   1
 Total symlinks:                0
 Total blocks (validated):      4 (avg. block size 131072000 B)
 Minimally replicated blocks:   4 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    3
 Average block replication:     3.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          4
 Number of racks:               1
FSCK ended at Tue Nov 15 05:51:12 EST 2016 in 0 milliseconds
The filesystem under path '/user/spinatelli/teragen_data/part-m-00000' is HEALTHY
```

